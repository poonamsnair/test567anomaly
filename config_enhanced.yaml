# Enhanced AI Agent Trajectory Anomaly Detection System Configuration

# Data Generation Configuration (unchanged)
data_generation:
  num_normal_trajectories: 1000
  trajectory_patterns:
    simple_linear: {min_nodes: 5, max_nodes: 10, weight: 0.3}
    branched_analysis: {min_nodes: 10, max_nodes: 20, weight: 0.25}
    multi_agent_handoffs: {min_nodes: 15, max_nodes: 25, weight: 0.2}
    complex_research: {min_nodes: 20, max_nodes: 40, weight: 0.15}
    error_recovery: {min_nodes: 10, max_nodes: 30, weight: 0.1}
  
  agent_types:
    - Planner
    - Executor
    - Validator
    - Coordinator
  
  tool_types:
    - web_search
    - read_document
    - prepare_document
    - analyze_data
    - deep_research
    - write_code
    - memory_store_retrieve
    - external_api

# Enhanced Anomaly Injection Configuration
anomaly_injection:
  total_anomalous_trajectories: 200
  anomaly_types:
    infinite_loops: {severity: critical, ratio: 0.15}
    suboptimal_paths: {severity: medium, ratio: 0.15}
    tool_failure_cascades: {severity: high, ratio: 0.12}
    planning_paralysis: {severity: medium, ratio: 0.10}
    memory_inconsistencies: {severity: high, ratio: 0.10}
    timeout_cascades: {severity: high, ratio: 0.10}
    handoff_failures: {severity: critical, ratio: 0.08}
    validation_loops: {severity: medium, ratio: 0.08}
    context_drift: {severity: low, ratio: 0.07}
    incomplete_responses: {severity: critical, ratio: 0.05}
  
  severity_levels:
    low: {degradation_range: [0.1, 0.2], user_impact: minimal}
    medium: {degradation_range: [0.2, 0.4], user_impact: noticeable}
    high: {degradation_range: [0.4, 0.7], user_impact: significant}
    critical: {degradation_range: [0.7, 1.0], user_impact: system_failure}

# Enhanced Graph Processing Configuration
graph_processing:
  # Enhanced Node2Vec with expanded parameter ranges
  node2vec:
    dimensions: [64, 128, 256, 512]
    walk_length: [20, 30, 50, 80, 100]
    num_walks: [100, 200, 500, 1000, 1500]
    p: [0.25, 0.5, 1.0, 2.0, 4.0]
    q: [0.25, 0.5, 1.0, 2.0, 4.0]
    window: [5, 10, 15, 20]
    min_count: [1, 3, 5, 10]
    workers: 4
    optimization_method: 'bayesian'
    n_iterations: 50
  
  # Enhanced DeepWalk with expanded parameter ranges
  deepwalk:
    dimensions: [64, 128, 256, 512]
    walk_length: [20, 40, 80, 120, 160]
    num_walks: [50, 80, 200, 400, 800]
    window: [5, 10, 15, 20]
    min_count: [0, 1, 3, 5]
    sg: 1
    optimization_method: 'bayesian'
    n_iterations: 50
  
  # Enhanced GraphSAGE configuration
  graphsage:
    hidden_dims: [[32, 64], [64, 128], [128, 256], [256, 512]]
    output_dim: [64, 128, 256]
    learning_rate: [0.0001, 0.001, 0.01, 0.1]
    epochs: [50, 100, 200, 300]
    batch_size: [16, 32, 64, 128]
    dropout: [0.1, 0.2, 0.3, 0.4]
    aggregator: ['mean', 'max', 'lstm']
    optimization_method: 'bayesian'
    n_iterations: 30
  
  aggregation_methods:
    - mean
    - max
    - sum
    - weighted_mean
    - attention_weighted
  
  centrality_measures:
    - betweenness
    - closeness
    - eigenvector
    - pagerank
    - katz

# Enhanced Feature Engineering Configuration
feature_engineering:
  # Advanced structural features
  structural_features:
    - density
    - diameter
    - average_shortest_path_length
    - betweenness_centrality
    - closeness_centrality
    - eigenvector_centrality
    - pagerank_centrality
    - katz_centrality
    - clustering_coefficient
    - transitivity
    - longest_path_length
    - number_connected_components
    - node_connectivity
    - edge_connectivity
    - assortativity
    - global_efficiency
    - local_efficiency
  
  # Enhanced DAG-specific features
  dag_features:
    - dag_depth
    - dag_longest_path
    - dag_width
    - level_statistics
    - branching_factor
    - parallel_paths
    - execution_gaps
    - concurrency_estimate
    - temporal_consistency
    - temporal_anomalies
    - critical_path_analysis
    - resource_utilization
  
  # Enhanced temporal features
  temporal_features:
    - duration_statistics
    - execution_patterns
    - timing_anomalies
    - temporal_sequences
    - performance_trends
    - seasonality_patterns
    - burst_detection
    - idle_time_analysis
  
  # Enhanced semantic features
  semantic_features:
    - error_patterns
    - recovery_patterns
    - agent_behavior
    - tool_usage_patterns
    - success_patterns
    - context_consistency
    - semantic_similarity
    - behavior_clustering
  
  # Advanced graph structure features
  graph_structure_features:
    enabled: true
    adjacency_features: true
    edge_attribute_features: true
    degree_features: true
    connectivity_features: true
    centrality_distribution_features: true
    path_features: true
    topology_features: true
    spectral_features: true
    community_features: true

# Enhanced Model Configuration
models:
  # Enhanced Isolation Forest Configuration
  isolation_forest:
    enabled: true
    hyperparameter_tuning: true
    optimization_method: 'bayesian'  # Bayesian optimization
    n_iterations: 100
    parallel_jobs: 4
    
    # Expanded parameter ranges
    n_estimators: [100, 200, 300, 500, 1000]
    contamination: [0.01, 0.03, 0.05, 0.08, 0.1, 0.15, 0.2, 'auto']
    max_features: [0.3, 0.5, 0.7, 0.85, 1.0, 'sqrt', 'log2']
    max_samples: [0.3, 0.5, 0.7, 0.85, 1.0, 'auto']
    bootstrap: [True, False]
    warm_start: [True, False]
    random_state: 42
    
    # Ensemble configuration
    ensemble:
      enabled: true
      n_models: 5
      diversity_threshold: 0.1
      voting_method: 'soft'
    
    # Advanced feature selection
    feature_selection:
      enabled: true
      methods: ['mutual_info', 'f_test', 'recursive_elimination', 'isolation_forest_importance']
      selection_strategy: 'ensemble'
      n_features_range: [0.3, 0.8]
      cross_validation: true
      cv_folds: 5
  
  # Enhanced One-Class SVM Configuration
  one_class_svm:
    enabled: true
    hyperparameter_tuning: true
    optimization_method: 'bayesian'
    n_iterations: 80
    parallel_jobs: 4
    
    # Multi-kernel approach
    kernels: ['rbf', 'linear', 'poly', 'sigmoid']
    kernel_combinations: true
    
    # Expanded parameter ranges
    gamma: ['scale', 'auto', 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0]
    nu: [0.01, 0.03, 0.05, 0.08, 0.1, 0.15, 0.2, 0.25, 0.3]
    degree: [2, 3, 4, 5]  # For poly kernel
    coef0: [0.0, 0.1, 0.5, 1.0]  # For poly and sigmoid
    
    # Advanced preprocessing
    preprocessing:
      scaling_methods: ['standard', 'robust', 'quantile', 'power']
      dimensionality_reduction:
        enabled: true
        methods: ['pca', 'kernel_pca', 'incremental_pca']
        n_components_range: [0.8, 0.95]
        kernel_pca_kernels: ['rbf', 'poly', 'sigmoid']
      
      # Feature transformation
      feature_transformation:
        enabled: true
        methods: ['quantile_uniform', 'quantile_normal', 'power_yeo_johnson']
    
    # Ensemble configuration
    ensemble:
      enabled: true
      combination_method: 'stacking'
      meta_learner: 'ridge'
  
  # Enhanced GNN Autoencoder Configuration
  gnn_autoencoder:
    enabled: true
    hyperparameter_tuning: true
    optimization_method: 'bayesian'
    n_iterations: 50
    parallel_jobs: 2  # GPU intensive
    
    # Advanced architecture options
    architectures: ['standard', 'variational', 'attention', 'transformer']
    
    # Expanded parameter ranges
    hidden_dims: [[64, 128], [128, 256], [256, 512], [128, 256, 512], [64, 128, 256, 128, 64]]
    latent_dims: [32, 64, 128, 256]
    edge_dim: [8, 16, 32, 64]
    
    # Advanced GNN types
    gnn_types: ['GCN', 'GAT', 'GraphConv', 'TransformerConv', 'SAGEConv', 'GINConv']
    
    # Training parameters
    learning_rate: [0.0001, 0.001, 0.01, 0.1]
    batch_size: [8, 16, 32, 64]
    epochs: [100, 200, 300, 500]
    dropout: [0.1, 0.2, 0.3, 0.4, 0.5]
    weight_decay: [0.0, 0.0001, 0.001, 0.01]
    
    # Attention mechanisms
    attention:
      enabled: true
      heads: [1, 2, 4, 8]
      attention_dropout: [0.1, 0.2, 0.3]
      global_attention: true
    
    # Variational components
    variational:
      enabled: true
      beta: [0.1, 0.5, 1.0, 2.0]  # KL divergence weight
      reparameterization: true
    
    # Graph augmentation
    augmentation:
      enabled: true
      methods: ['node_dropout', 'edge_dropout', 'feature_masking', 'subgraph_sampling']
      node_dropout_rate: [0.1, 0.2, 0.3]
      edge_dropout_rate: [0.1, 0.2, 0.3]
      feature_masking_rate: [0.1, 0.15, 0.2]
      subgraph_ratio: [0.7, 0.8, 0.9]
    
    # Advanced loss functions
    loss_functions:
      reconstruction_loss: ['mse', 'mae', 'huber']
      structure_loss: ['adjacency', 'laplacian', 'spectral']
      contrastive_loss: ['infonce', 'triplet', 'margin']
      loss_weights:
        reconstruction: [1.0, 0.8, 0.6]
        structure: [0.1, 0.05, 0.02]
        contrastive: [0.1, 0.05, 0.02]
        kl_divergence: [0.1, 0.05, 0.01]
    
    # Early stopping
    early_stopping:
      enabled: true
      patience: [10, 15, 20, 25]
      min_delta: [1e-6, 1e-5, 1e-4]
      restore_best_weights: true
    
    # Learning rate scheduling
    lr_scheduler:
      enabled: true
      scheduler_type: ['reduce_on_plateau', 'cosine_annealing', 'exponential']
      patience: [5, 10, 15]
      factor: [0.5, 0.7, 0.9]

# Enhanced Ensemble Configuration
ensemble:
  enabled: true
  
  # Advanced optimization methods
  optimization_methods: ['bayesian_optimization', 'genetic_algorithm', 'particle_swarm']
  
  # Multiple fusion strategies
  fusion_methods: ['weighted_average', 'stacking', 'voting', 'meta_learning']
  
  # Meta-learning configuration
  meta_learning:
    enabled: true
    meta_model: 'neural_network'
    hidden_layers: [64, 32]
    dropout: 0.2
    learning_rate: 0.001
    epochs: 100
  
  # Advanced weighting strategies
  weighting_strategies:
    - performance_based
    - diversity_based
    - confidence_based
    - adaptive_weighting
  
  # Ensemble diversity measures
  diversity_measures:
    - disagreement_measure
    - q_statistic
    - correlation_coefficient
    - entropy_measure
  
  # Base model selection
  base_models:
    - isolation_forest
    - one_class_svm
    - gnn_autoencoder
  
  # Dynamic ensemble configuration
  dynamic_ensemble:
    enabled: true
    adaptation_method: 'online_learning'
    window_size: 100
    adaptation_rate: 0.1

# Enhanced Evaluation Configuration
evaluation:
  # Advanced data splitting
  data_split:
    strategy: 'stratified'
    train_ratio: 0.6
    validation_ratio: 0.2
    test_ratio: 0.2
    cross_validation: true
    cv_folds: 5
  
  # Advanced threshold calibration
  threshold_calibration:
    methods: ['roc_optimization', 'pr_optimization', 'f1_maximization', 'youden_index', 'knee_point_detection']
    ensemble_calibration: true
    probabilistic_calibration: true
  
  # Comprehensive evaluation metrics
  metrics:
    # Standard metrics
    - precision
    - recall
    - f1
    - accuracy
    - specificity
    - npv
    - auc_roc
    - auc_pr
    - average_precision
    
    # Clustering metrics
    - silhouette_score
    - calinski_harabasz_score
    - davies_bouldin_score
    - adjusted_rand_index
    
    # Anomaly detection specific
    - detection_latency
    - false_positive_clustering
    - severity_weighted_performance
    - anomaly_coverage
    - stability_index
    
    # Advanced metrics
    - matthew_correlation_coefficient
    - cohen_kappa
    - balanced_accuracy
    - geometric_mean
    - fowlkes_mallows_index

# Enhanced Visualization Configuration
visualization:
  # Advanced graph layouts
  graph_layouts:
    - spring
    - hierarchical
    - circular
    - kamada_kawai
    - spectral
    - shell
  
  # Enhanced color schemes
  color_schemes:
    node_types: viridis
    agent_types: Set3
    anomaly_severity: Reds
    performance: plasma
    centrality: coolwarm
  
  # High-quality figure settings
  figure_settings:
    dpi: 300
    format: png
    bbox_inches: tight
    style: seaborn
    figsize: [12, 8]
  
  # Advanced interactive features
  interactive:
    enabled: true
    renderer: browser
    animation: true
    3d_visualization: true
    real_time_updates: true

# Enhanced System Configuration
system:
  # Advanced parallel processing
  parallel_processing:
    enabled: true
    n_jobs: -1  # Use all available cores
    backend: 'threading'  # or 'multiprocessing'
    batch_size: 1000
    chunk_size: 100
  
  # Advanced memory management
  memory_management:
    limit_gb: 32
    gc_threshold: 0.8
    use_memory_mapping: true
    cache_size_gb: 4
  
  # Advanced caching
  caching:
    enabled: true
    cache_dir: './cache'
    feature_cache: true
    model_cache: true
    embedding_cache: true
    ttl_hours: 24
  
  # Enhanced logging
  logging:
    level: INFO
    format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    file: logs/enhanced_anomaly_detection.log
    rotation: daily
    max_size_mb: 100
    backup_count: 7
  
  # Performance monitoring
  monitoring:
    enabled: true
    metrics: ['cpu_usage', 'memory_usage', 'gpu_usage', 'training_time']
    profiling: true
    benchmark: true
  
  # Random seed for reproducibility
  random_seed: 42
  
  # Output directories
  output_dirs:
    models: models/
    charts: charts/
    data: data/
    logs: logs/
    cache: cache/
    benchmarks: benchmarks/